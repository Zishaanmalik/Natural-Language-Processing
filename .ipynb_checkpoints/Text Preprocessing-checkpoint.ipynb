{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cad20f-0b41-4eb6-9fad-1232339e099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root=Path(\"data\")\n",
    "root.mkdir(exist_ok=True)\n",
    "path=Path(root)/\"IMDB Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201a8583-c999-420d-aace-f44e20226d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ad7606-f434-42cb-9c7e-1b03bd6a8403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2891365-eaff-44d7-bb3b-19d4c6fe3d49",
   "metadata": {},
   "source": [
    "# 1. lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cdfe4a6-1cba-4fea-b31b-bc7b89a3c0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcf12c0-21b1-4129-a1ff-a15a644b0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7371fbaa-e862-49ac-9a8a-0f5de466152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c4af6-0a30-442e-83dd-347a8b6c6d28",
   "metadata": {},
   "source": [
    "# 2. remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8580e8-b296-47e9-a3d7-7bb9d04eaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ca8d71-09d4-4c86-bf90-dc8d9be3b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<html><body><p>from river to the sea Palestine will be Free </p><p> Free palestine </p><p> Click here to <a href='http://google.com'>download</a></p></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b6f050-f662-4a43-bf58-37db9396a55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from river to the sea Palestine will be Free  Free palestine  Click here to download'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251a47d9-35d8-4cc6-b3d1-3962b78c1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e1b9c1-9f7d-4cda-8913-ba869bf294cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4aa844-ebda-4b25-a54e-8e35f73d9faf",
   "metadata": {},
   "source": [
    "## 3. remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed94b2b-9747-400a-bcd8-517510cb3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1524efac-408a-45aa-9b14-f1504139bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Check out my notebook https://www.ziza.com/mybook1/notebook8223fc1abb. i want nothing.'\n",
    "text2 = 'Check out my notebook http://www.zidr.com/mybook1/notebook8223fc1abb'\n",
    "text3 = 'Google search here www.google.com'\n",
    "text4 = 'For notebook click https://www.free.com/mybook1/notebook8223fc1abb to search check www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6748977-7188-4e7f-92ec-79ce65d42163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my notebook  i want nothing.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef53c88-29ae-46eb-91b7-f6ce7f7f8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a882cdc-ca04-411f-b952-1f93e57f63b5",
   "metadata": {},
   "source": [
    "## 4. remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be826897-4ab0-47bc-865e-b895581e694a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3b91f5-dbc9-4cb2-a470-96c363085719",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b3bcfd7-d192-490d-ad75-06fab3bad040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ed8efb2-7b48-4dbb-a4a4-8f67e49808ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'string. With. Punctuation?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d9d7385-ef52-444e-ba34-569c55b5d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With Punctuation\n",
      "12.242794036865234\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punc(text))\n",
    "time1 = time.time() - start\n",
    "print(time1*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e72a9d55-94d8-4d1a-a7ed-47ebc53e021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this because this very fast\n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e94d2937-530b-4d60-8684-796b095c177b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.008148193359375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "remove_punc1(text)\n",
    "time2 = time.time() - start\n",
    "print(time2*50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa10ec1-5e5b-4d0b-b820-43b779607474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0376984126984126"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1/time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e411746-a542-4181-8acd-a82c69ba822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times in the last 25 years. paul lukas\\' performance brings tears to my eyes, and bette davis, in one of her very few truly sympathetic roles, is a delight. the kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. and the mother\\'s slow awakening to what\\'s happening in the world and under her own roof is believable and startling. if i had a dozen thumbs, they\\'d all be \"up\" for this movie.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8de13a4d-9335-4601-9d08-044596c86c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc1(df['review'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42e7acde-5a0f-45e2-b0ce-29b2f7fe677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_punc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe12f0b-e3cc-4474-99cf-cd1c87f4e72f",
   "metadata": {},
   "source": [
    "## 5. chat(short) words treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a7edb19-81bf-41c1-8d4d-a691cabe999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2=Path(root)/\"short words.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884d9db6-c563-475a-9d8b-960ede7dc927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acronym</th>\n",
       "      <th>expansion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2day</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2m2h</td>\n",
       "      <td>too much too handle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2moro</td>\n",
       "      <td>tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nite</td>\n",
       "      <td>tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4eae</td>\n",
       "      <td>for ever and ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>yw</td>\n",
       "      <td>you are welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>ywca</td>\n",
       "      <td>young womens christian association</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>ywimc</td>\n",
       "      <td>your wish is my command</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>ywsyls</td>\n",
       "      <td>you win some you lose some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>ywu</td>\n",
       "      <td>yo waz up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3357 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acronym                           expansion\n",
       "0       2day                               today\n",
       "1       2m2h                 too much too handle\n",
       "2      2moro                            tomorrow\n",
       "3      2nite                             tonight\n",
       "4       4eae                   for ever and ever\n",
       "...      ...                                 ...\n",
       "3352      yw                     you are welcome\n",
       "3353    ywca  young womens christian association\n",
       "3354   ywimc             your wish is my command\n",
       "3355  ywsyls          you win some you lose some\n",
       "3356     ywu                           yo waz up\n",
       "\n",
       "[3357 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words=pd.read_csv(path2)\n",
    "chat_words.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64e7d000-180c-4aee-be2a-0c0c53690c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_dict = dict(zip(chat_words['acronym'].str.lower(), chat_words['expansion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ea4fedf-8cc1-4b55-bda5-ab6ce19500be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.lower() in chat_dict:\n",
    "            new_text.append(chat_dict[w.lower()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab23ed38-5545-4428-ac9d-df4b659f10a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today is the best'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('2day is the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e2c35d6-964a-4166-a65a-ea33ade9bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in my humble opinion happy ending high explosives is the best'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('IMHO he is the best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80229ff9-16de-4ce4-95d1-ed3b44458f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for your information delhi is the capital of india'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('FYI delhi is the capital of india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18bc3b8c-2b13-495c-9b8b-a771512d875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(chat_conversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5884e39-c34a-4a0c-9aaa-a4af69a80cb8",
   "metadata": {},
   "source": [
    "## 6. spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c73a3262-6cdb-428d-81f9-947659c9667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80ace6a0-3d64-480d-9ae5-099e3697577b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
    "incorrect_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d9caf9c-7b56-4073-bcdb-97801411d6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textBlb = TextBlob(incorrect_text)\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cef102b-b754-439f-a76c-577b800b4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelling_correction(text):\n",
    "    textBlb = TextBlob(text)\n",
    "    return textBlb.correct().string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e52d6a5-7661-42ee-a2b5-59fbb9a7ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61429.98933792114  sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res=spelling_correction(df['review'][5])\n",
    "time2 = time.time() - start\n",
    "print(time2*50000,' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b3901d0-93e7-442e-a1de-cc9cd1265d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#df['review'] = df['review'].apply(spelling_correction)\n",
    "#time2 = time.time() - start\n",
    "#print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2543d56-e1a1-4c93-8590-388e81558296",
   "metadata": {},
   "source": [
    "## 7. stop words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae8d0c-216e-48eb-82f4-5a70f12b4f62",
   "metadata": {},
   "source": [
    "#### Stop words are highâ€‘frequency words that serve mainly grammatical or structural purposes rather than conveying significant meaning.\n",
    "\n",
    "- Articles: a, an, the\n",
    "- Pronouns: I, you, he, she, it, we, they\n",
    "- Prepositions: in, on, at, of, to, with\n",
    "- Conjunctions: and, or, but, if\n",
    "- Auxiliary verbs: is, was, were, be, have, do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a2d8f1d-7f8e-498a-9873-b7cce76a2ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a data folder using pathlib\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download stopwords into this folder\n",
    "nltk.download(\"stopwords\", download_dir=str(data_dir))\n",
    "\n",
    "# Tell NLTK to look inside your custom folder\n",
    "nltk.data.path.append(str(data_dir))\n",
    "\n",
    "# Now you can use stopwords\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e73bd05f-3ca8-4a98-99ff-c2d25f47999c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "914e78a1-01e1-44f0-b0a8-f845bbd7a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac4859c2-a7bf-4f04-885c-00c2cb14ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in stop_words:\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b697272-fc5a-4f71-9381-b6bac96a5864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. it just never gets old, despite my having seen it some 15 or more times\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b3aa8b-3e6d-4947-aa6a-d769b4ae9385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c65ce4c-4691-4e71-b0ea-c2243dd92098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this wait and see a wonderful where ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the tears in my eyes of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this wait and see a wonderful where ...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the tears in my eyes of...  positive"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ee89be2-d005-453a-bd8f-a8ddc49656b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.313873291015625  sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['review'].apply(remove_stopwords)\n",
    "time2 = time.time() - start\n",
    "print(time2,' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241559ef-6abb-4d22-b0c0-2e53215fc407",
   "metadata": {},
   "source": [
    "## 8. handling Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3bec802-a655-4f82-9df8-fab486d40530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove or replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75b33fc1-5006-4143-bdbb-5ae285303c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0fbf3d1-9264-48e4-80e6-af85551202fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df04de6a-1479-4df7-af82-201858a5e838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was ðŸ˜˜ðŸ˜˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98b5a318-f2fd-4260-9c94-1b81a864a3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lmao '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Lmao ðŸ˜‚ðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "218a0090-f0a4-42f2-9010-1adf9fb42db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf224d0b-7aa6-466e-b106-323811ac5f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is :fire:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Python is ðŸ”¥'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dce123d5-039e-4f47-b13b-836949df3840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loved the movie. It was :face_blowing_a_kiss:\n"
     ]
    }
   ],
   "source": [
    "print(emoji.demojize('Loved the movie. It was ðŸ˜˜'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4833907c-24be-4392-a281-374be2a5b0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸ˜˜']\n"
     ]
    }
   ],
   "source": [
    "print(emoji.distinct_emoji_list('Loved the movie. It was ðŸ˜˜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479286d-35ac-47f1-887c-85bd683a674d",
   "metadata": {},
   "source": [
    "## 9. tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ece6a-b3b1-4243-83ad-d1c068dccaf5",
   "metadata": {},
   "source": [
    "#### 1. Using the split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "900b7ed1-58ab-4ded-b336-5ebaf1ce6c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ece84637-ea84-437c-aa35-5834c8b72618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d1f66e9b-df4e-4c26-b52b-41e8c11a1df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1c2a1-8777-49e2-946d-fc9d987dce82",
   "metadata": {},
   "source": [
    "#### 2. Using Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ef66f47-9b78-42ea-97c6-c507c4688715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce164f10-2493-4401-b6a4-4c9178b3ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72ada653-9b41-44dc-b02d-9c8a86f87319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.split(r'[.!?][\\n]', text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c846e-1bb7-4be1-97be-281b1762774c",
   "metadata": {},
   "source": [
    "#### 3. Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf471493-25aa-4754-84ee-02091cc7b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b13f6fb-a9dd-4383-95a7-58963940c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to D:\\data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to D:\\data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download punkt into this folder\n",
    "nltk.download(\"punkt\", download_dir=str(data_dir))\n",
    "nltk.download(\"punkt_tab\", download_dir=str(data_dir))\n",
    "\n",
    "# Tell NLTK to look inside your custom folder\n",
    "nltk.data.path.append(str(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09dee5ed-19fc-443f-9346-44d135462ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to visit delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "287dbf15-362b-48ae-84ef-30e61338923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e886cfdc-fede-4eb9-ae78-1915885b1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d78bc8a6-7482-406e-bc54-962ee1bbd55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5cb6c2bd-ed65-42cb-a86b-ab96eae15c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'nks',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73117521-f1b3-4448-b041-ac39231eda08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', '5km', 'ride', 'cost', '$', '10.50']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182126fb-f1f6-49a2-a943-a8d64be190a0",
   "metadata": {},
   "source": [
    "#### 4. Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7c48a4b-ee73-4001-a3cd-5ab35578f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01faf248-5a0c-4a1b-9ff7-2de29d0730f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d023aaa5-6ac9-4cdd-b7ff-99f4c726477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a Ph.D in A.I\n",
      "We're here to help! mail us at nks@gmail.com\n",
      "A 5km ride cost $10.50\n",
      "I am going to visit delhi!\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(sent5)\n",
    "print(doc1)\n",
    "doc2 = nlp(sent6)\n",
    "print(doc2)\n",
    "doc3 = nlp(sent7)\n",
    "print(doc3)\n",
    "doc4 = nlp(sent1)\n",
    "print(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9afe374c-ae67-4b02-ad9a-3f289b1c517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "mail\n",
      "us\n",
      "at\n",
      "nks@gmail.com\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a31ead67-7edf-43db-b1c7-6bbe8a9ad36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b38ba3d8-8994-4d8c-a065-14dc7a7b6d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lorem Ipsum is simply dummy text of the printing and typesetting industry? ,\n",
       " Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
       " when an unknown printer took a galley of type and scrambled it to make a type specimen book.]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = nlp(text)\n",
    "list(docs.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cda1c71-bc33-452e-b5c5-ba53e3e4f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry? \n",
      "\n",
      "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\n"
     ]
    }
   ],
   "source": [
    "for token in list(docs.sents):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063ff60-bb35-4279-a965-34218da9fc65",
   "metadata": {},
   "source": [
    "#### 10. Stemming or Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bd0ef-41a2-4d76-8d94-5b641c7a92bf",
   "metadata": {},
   "source": [
    "`Inflection` is the process by which words change their form to indicate grammatical features such as tense, number, case, gender, mood, or person.\n",
    "\n",
    "- Example: walk â†’ walked (past tense)\n",
    "- Example: child â†’ children (plural form)\n",
    "- Example: he sit â†’ he sits (third person singular verb form)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a3d7c-11a6-440a-856f-260778879407",
   "metadata": {},
   "source": [
    "#### Stemming: cuts words down to their root form by chopping off prefixes/suffixes, often producing nonâ€‘dictionary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4432bdba-36e2-493f-aa65-45dbe61ccc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f15ba1e0-ed9d-4ab2-a152-3778dd712f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bfa22b4-4d34-4ca7-a474-fae8697c41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "face142f-4d37-48f6-ad88-382d94d2a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
     ]
    }
   ],
   "source": [
    "text = 'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d91d7afb-dcde-4487-be0c-ec16b697f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a397b-6ead-466c-b975-73fa8fbea0f2",
   "metadata": {},
   "source": [
    "#### Lemmatization: reduces words to their meaningful dictionary base form (lemma), using linguistic rules and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "511fff85-1090-4e3a-8a18-3b525f2ac82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to D:\\data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to D:\\data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to D:\\data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pathlib import Path\n",
    "\n",
    "# Define your custom data folder on D: drive\n",
    "data_dir = Path(\"D:/data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Download WordNet into this folder\n",
    "nltk.download(\"wordnet\", download_dir=str(data_dir))\n",
    "nltk.download(\"omw-1.4\", download_dir=str(data_dir))  # optional, improves lemmatization\n",
    "nltk.download(\"punkt\", download_dir=str(data_dir))    # for tokenization\n",
    "\n",
    "# Tell NLTK to look inside your custom folder\n",
    "nltk.data.path.append(str(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c20fce09-c822-4c2f-9ea6-ebcae93870b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n"
     ]
    }
   ],
   "source": [
    "# Test: use WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "print(wordnet_lemmatizer.lemmatize(\"walked\", pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "358e5922-f1b4-4307-a86d-c6f8849bb72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('', '', exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59a5a856-2a95-4df8-a1a3-06615c1195bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence=remove_punc1(sentence)\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2d885-da94-4725-b363-9ea0fe4c7d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd272b0-75ee-4726-aadf-498fd81d8638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
